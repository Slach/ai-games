# syntax=docker/dockerfile:1-labs
ARG CUR_DIR=.
ARG UBUNTU_VERSION=24.04
# This needs to generally match the container host's environment.
ARG CUDA_VERSION=13.0.2
# Target the CUDA build image
ARG BASE_CUDA_DEV_CONTAINER=nvidia/cuda:${CUDA_VERSION}-devel-ubuntu${UBUNTU_VERSION}

ARG BASE_CUDA_RUN_CONTAINER=nvidia/cuda:${CUDA_VERSION}-runtime-ubuntu${UBUNTU_VERSION}

FROM ${BASE_CUDA_DEV_CONTAINER} AS comfyui
LABEL org.opencontainers.image.description="ComfyUI backend and GUI (ARM64) for NVIDIA GB10"
LABEL maintainer="Eugene Klimov <bloodjazman@gmail.com>"

# Install system dependencies
RUN apt update && apt install -y \
    python3 \
    python3-pip \
    python3-venv \
    python3-dev \
    git \
    wget \
    curl \
    build-essential \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgtk-3-dev \
    libglx0 \
    libglib2.0-0 \
    yq \
    && apt autoremove && apt clean && apt autoclean \
    && rm -rf /var/lib/apt/lists/*

# Install uv using --break-system-packages due to PEP 668
RUN pip3 install --break-system-packages uv

# Install PyTorch with CUDA 13 support for ARM64
ENV LD_LIBRARY_PATH=/usr/local/cuda-13/compat
RUN uv pip install --no-cache --system --break-system-packages --upgrade pip && \
    uv pip install --no-cache --system --break-system-packages torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130


RUN uv pip install --no-cache --system --break-system-packages huggingface_hub[cli]

# get latest release for ComfyUI
# Clone ComfyUI
# @todo use https://github.com/Comfy-Org/ComfyUI
RUN COMFYUI_VERISION=$(curl -sL https://github.com/comfyanonymous/ComfyUI/releases/latest -H "Accept: application/json" | jq -r .tag_name) && \
   git clone --depth 1 --branch "${COMFYUI_VERISION}"  https://github.com/comfyanonymous/ComfyUI.git /opt/ComfyUI
WORKDIR /opt/ComfyUI


# Install ComfyUI requirements
RUN python3 -m venv --system-site-packages /opt/ComfyUI/.venv
RUN grep -vE '^\s*#' requirements.txt | grep -viE '^\s*(torch|torchvision|torchaudio)\b' > /opt/ComfyUI/requirements.no_torch.txt
RUN grep -vE '^\s*#' manager_requirements.txt | grep -viE '^\s*(torch|torchvision|torchaudio)\b' > /opt/ComfyUI/manager_requirements.no_torch.txt

RUN COMFYUI_MANAGER_VERSION=$(curl -s https://api.github.com/repos/Comfy-Org/ComfyUI-Manager/tags | jq -r '.[].name' | head -n 1) && \
# todo WTF, why cm-cli.py exists only in main ? but not exists in latest release tag?
#    git clone --depth 1 --branch "${COMFYUI_MANAGER_VERSION}" https://github.com/Comfy-Org/ComfyUI-Manager.git /opt/ComfyUI/custom_nodes/ComfyUI-Manager && \
    git clone --depth 1 https://github.com/Comfy-Org/ComfyUI-Manager.git /opt/ComfyUI/custom_nodes/ComfyUI-Manager 

RUN uv pip install --no-cache -r /opt/ComfyUI/custom_nodes/ComfyUI-Manager/requirements.txt
RUN uv pip install --no-cache comfy-cli

RUN uv pip install --no-cache --no-deps -r /opt/ComfyUI/requirements.no_torch.txt
RUN uv pip install --no-cache --no-deps -r /opt/ComfyUI/manager_requirements.no_torch.txt 

ENV COMFYUI_PATH=/opt/ComfyUI/

# check torch versions
RUN /usr/bin/python3 -c "import torch; print('SYSTEM', torch.__version__, torch.version.cuda, torch.__file__)"
RUN /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.version.cuda, torch.__file__)"

# Install ComfyUI custom-nodes

# Clone ComfyUI-TRELLIS2 directly and install it to ensure CUDA detection works
RUN git clone --depth=1 https://github.com/PozzettiAndrea/ComfyUI-TRELLIS2 /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2
# Fix platform compatibility for wheel installation
RUN pip config set global.break-system-packages true
RUN grep -vE '^\s*#' /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2/requirements.txt | grep -viE '^\s*(torch|torchvision|torchaudio)\b' > /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2/requirements.no_torch.txt
RUN --device=nvidia.com/gpu uv pip install --no-deps -r /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2/requirements.no_torch.txt
# manually install, based on https://github.com/PozzettiAndrea/nvdiffrec_render-wheels/blob/main/.github/workflows/build-cu130-torch291.yml 
# todo remove all before install.py, after fix https://github.com/PozzettiAndrea/nvdiffrec_render-wheels/issues/1 and https://github.com/PozzettiAndrea/ComfyUI-TRELLIS2/issues/38 
RUN --device=nvidia.com/gpu apt install -y \
            cuda-nvcc-13-0 \
            cuda-cudart-dev-13-0 \
            libcublas-dev-13-0 \
            libcusparse-dev-13-0 \
            libcurand-dev-13-0 \
            libcufft-dev-13-0 \
            libcusolver-dev-13-0 \
            cuda-nvtx-13-0

ENV PATH="/usr/local/cuda-13.0/bin:${PATH}"
ENV CUDA_HOME=/usr/local/cuda-13.0
ENV CUDA_PATH=/usr/local/cuda-13.0
ENV TORCH_SHORT=291
ENV TORCH_MM=29
ENV TORCH_CUDA_ARCH_LIST='12.1'

RUN uv pip install --no-cache wheel setuptools ninja

RUN mkdir -p /tmp/nvdiffrec_render-wheels/

RUN git clone --depth=1 https://github.com/PozzettiAndrea/nvdiffrec_render-wheels/ /tmp/nvdiffrec_render-wheels/ && \
    cd /tmp/nvdiffrec_render-wheels/ && \
    git clone --depth=1 https://github.com/NVlabs/nvdiffrec.git && \
    mkdir -p nvdiffrec_render_pkg && \
    cp -rf nvdiffrec/render nvdiffrec_render_pkg/nvdiffrec_render && \
    cp -vf setup.py nvdiffrec_render_pkg/
# replace JIT compilation to static import
COPY comfyui/nvdiffrec_ops.py /tmp/nvdiffrec_render-wheels/nvdiffrec_render_pkg/nvdiffrec_render/renderutils/ops.py
RUN --device=nvidia.com/gpu cd /tmp/nvdiffrec_render-wheels/nvdiffrec_render_pkg && \
          /opt/ComfyUI/.venv/bin/pip install --no-build-isolation .

RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2/install.py

RUN /opt/ComfyUI/.venv/bin/comfy --skip-prompt --no-enable-telemetry node install https://github.com/nunchaku-tech/ComfyUI-nunchaku
RUN /opt/ComfyUI/.venv/bin/comfy --skip-prompt --no-enable-telemetry node install https://github.com/filliptm/ComfyUI_Fill-ChatterBox

# Install ComfyUI models 

CMD ["/opt/ComfyUI/.venv/bin/python3", "main.py", "--enable-manager","--preview-method auto", "--front-end-version Comfy-Org/ComfyUI_frontend@latest"]

EXPOSE 8188

