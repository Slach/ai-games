# syntax=docker/dockerfile:1-labs
ARG NPROC=8
ARG CUR_DIR=.
ARG UBUNTU_VERSION=24.04
# This needs to generally match the container host's environment.
ARG CUDA_VERSION=13.0.2
# Target the CUDA build image
ARG BASE_CUDA_DEV_CONTAINER=nvidia/cuda:${CUDA_VERSION}-devel-ubuntu${UBUNTU_VERSION}

ARG BASE_CUDA_RUN_CONTAINER=nvidia/cuda:${CUDA_VERSION}-runtime-ubuntu${UBUNTU_VERSION}

FROM ${BASE_CUDA_DEV_CONTAINER} AS comfyui
LABEL org.opencontainers.image.description="ComfyUI backend and GUI (ARM64) for NVIDIA GB10"
LABEL maintainer="Eugene Klimov <bloodjazman@gmail.com>"
ARG NPROC

# Install system dependencies
RUN apt update && apt install -y \
    python3 \
    python3-pip \
    python3-venv \
    python3-dev \
    git \
    wget \
    curl \
    build-essential \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgtk-3-dev \
    libglx0 \
    libglib2.0-0 \
    ninja-build \
    cmake \
    make \
    yq \
    # need for decord
    ffmpeg \
    libavcodec-dev \
    libavfilter-dev \ 
    libavformat-dev \
    libavutil-dev \
    libavcodec60 \
    libavfilter9 \
    libavformat60 \
    libavutil58 \
    && apt autoremove && apt clean && apt autoclean \
    && rm -rf /var/lib/apt/lists/*

# Install uv using --break-system-packages due to PEP 668
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ pip3 install --break-system-packages uv

# Copy the fix_conflicts.py script
COPY comfyui/fix_conflicts.py /opt/fix_conflicts.py

# Install PyTorch with CUDA 13 support for ARM64
ENV LD_LIBRARY_PATH=/usr/local/cuda-13/compat:$LD_LIBRARY_PATH
ENV LD_LIBRARY_PATH=/opt/ComfyUI/.venv/lib/python3.12/site-packages/torch/lib:$LD_LIBRARY_PATH

RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ uv pip install --system --break-system-packages --upgrade pip
# Run pip freeze to capture state after pip upgrade
RUN pip freeze > /opt/pip_freeze_after_pip_upgrade.txt
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ uv pip install --system --break-system-packages huggingface_hub[cli]
# Run pip freeze to capture state after huggingface_hub installation
RUN pip freeze > /opt/pip_freeze_after_hf.txt

# Increase parallelism for build environment
ENV CMAKE_GENERATOR=Ninja
ENV CC=gcc
ENV CXX=g++
ENV MAX_JOBS=${NPROC}
ENV CUDA_NVCC_FLAGS="-arch=sm_121 -code=sm_121 --ptxas-options=--threads=${NPROC}"
ENV CMAKE_BUILD_PARALLEL_LEVEL=${NPROC}
ENV MAKEFLAGS="-j${NPROC}"
RUN git config --global submodule.fetchJobs ${NPROC} && git config --global fetch.parallel ${NPROC}

ENV PATH="/usr/local/cuda-13.0/bin:${PATH}"
ENV CUDA_HOME=/usr/local/cuda-13.0
ENV CUDA_PATH=/usr/local/cuda-13.0
ENV TORCH_CUDA_ARCH_LIST="12.1"

# get latest release for ComfyUI
# Clone ComfyUI
# @todo use https://github.com/Comfy-Org/ComfyUI
RUN COMFYUI_VERISION=$(curl -sL https://github.com/comfyanonymous/ComfyUI/releases/latest -H "Accept: application/json" | jq -r .tag_name) && \
   git clone --depth 1 --branch "${COMFYUI_VERISION}"  https://github.com/comfyanonymous/ComfyUI.git /opt/ComfyUI
WORKDIR /opt/ComfyUI
RUN python3 -m venv --system-site-packages /opt/ComfyUI/.venv
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu uv pip install wheel setuptools ninja numpy
# Run pip freeze to capture state after basic packages installation
RUN pip freeze > /opt/pip_freeze_after_basic_packages.txt


# Install ComfyUI requirements
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ uv pip install --break-system-packages torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130
# Run pip freeze to capture state after PyTorch installation
RUN pip freeze > /opt/pip_freeze_after_pytorch.txt

RUN grep -vE '^\s*#' requirements.txt | grep -viE '^\s*(torch|torchvision|torchaudio)\b' > /opt/ComfyUI/requirements.no_torch.txt
RUN grep -vE '^\s*#' manager_requirements.txt | grep -viE '^\s*(torch|torchvision|torchaudio)\b' > /opt/ComfyUI/manager_requirements.no_torch.txt

RUN COMFYUI_MANAGER_VERSION=$(curl -s https://api.github.com/repos/Comfy-Org/ComfyUI-Manager/tags | jq -r '.[].name' | head -n 1) && \
# todo WTF, why cm-cli.py exists only in main ? but not exists in latest release tag?
#    git clone --depth 1 --branch "${COMFYUI_MANAGER_VERSION}" https://github.com/Comfy-Org/ComfyUI-Manager.git /opt/ComfyUI/custom_nodes/ComfyUI-Manager && \
    git clone --depth 1 https://github.com/Comfy-Org/ComfyUI-Manager.git /opt/ComfyUI/custom_nodes/ComfyUI-Manager 

RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ uv pip install -r /opt/ComfyUI/custom_nodes/ComfyUI-Manager/requirements.txt
# Run pip freeze to capture state after ComfyUI Manager requirements installation
RUN pip freeze > /opt/pip_freeze_after_manager_requirements.txt
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ uv pip install comfy-cli
# Run pip freeze to capture state after comfy-cli installation
RUN pip freeze > /opt/pip_freeze_after_comfy_cli.txt

RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ uv pip install -r /opt/ComfyUI/requirements.no_torch.txt
# Run pip freeze to capture state after ComfyUI requirements installation
RUN pip freeze > /opt/pip_freeze_after_comfyui_requirements.txt
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ uv pip install -r /opt/ComfyUI/manager_requirements.no_torch.txt
# Run pip freeze to capture state after manager requirements installation
RUN pip freeze > /opt/pip_freeze_after_manager_no_torch_requirements.txt

ENV COMFYUI_PATH=/opt/ComfyUI/

# flash_attn, sageattention for lightX2V
ENV FLASH_ATTN_CUDA_ARCHS=121
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu \
    /opt/ComfyUI/.venv/bin/pip install --no-build-isolation sageattention && \
    # Run pip freeze to capture state after sageattention installation
    pip freeze > /opt/pip_freeze_after_sageattention.txt && \
    /opt/ComfyUI/.venv/bin/python3 -c "import torch; from sageattention import sageattn; q = torch.randn(1, 1, 16, 64, device='cuda', dtype=torch.float16); out = sageattn(q, q, q); print('Segattention Test:', out.device)" && \
# todo wait when flash_attn support GB10 https://github.com/Dao-AILab/flash-attention/issues/1969
#    git clone --depth=1 --recursive https://github.com/Dao-AILab/flash-attention /opt/flash-attention && \
#    cd /opt/flash-attention/hopper && \
#    /opt/ComfyUI/.venv/bin/pip install ninja packaging && \
#    /opt/ComfyUI/.venv/bin/python setup.py install && \
    /opt/ComfyUI/.venv/bin/pip install --no-build-isolation flash_attn && \
    # Run pip freeze to capture state after flash_attn installation
    pip freeze > /opt/pip_freeze_after_flash_attn.txt && \
    /opt/ComfyUI/.venv/bin/python3 -c "import flash_attn; print('flash_attn OK', flash_attn.__version__)"

# Install ComfyUI custom-nodes

# Images nunchaku 
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu git clone --depth 1 https://github.com/nunchaku-tech/nunchaku.git /opt/nunchaku && \
    cd /opt/nunchaku && \
    git submodule init && \
    git submodule update --jobs 20 --depth 1 && \
    git submodule foreach --recursive 'git submodule init && git submodule update --jobs 20 --depth 1' && \
    /opt/ComfyUI/.venv/bin/pip install Cython && \
    # Run pip freeze to capture state after Cython installation
    pip freeze > /opt/pip_freeze_after_cython.txt && \
    /opt/ComfyUI/.venv/bin/pip install --no-build-isolation -e ".[dev,docs]" && \
    # Run pip freeze to capture state after nunchaku installation
    pip freeze > /opt/pip_freeze_after_nunchaku.txt && \
    /opt/ComfyUI/.venv/bin/python3 -c "from nunchaku import ops; print('nunchaku ops OK')"

RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.__file__, torch.version.cuda, torch.cuda.is_available(), torch.device(torch.cuda.current_device()) )"

RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/comfy --skip-prompt --no-enable-telemetry node install https://github.com/nunchaku-tech/ComfyUI-nunchaku
RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.__file__, torch.version.cuda, torch.cuda.is_available(), torch.device(torch.cuda.current_device()) )"

# TTS chatterbox
# Install chatterbox-tts ignoring dependency conflicts
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu git clone --depth=1 https://github.com/resemble-ai/chatterbox.git /opt/chatterbox && \
    sed -i '/torch/d' /opt/chatterbox/pyproject.toml && \
    sed -i '/torchaudio/d' /opt/chatterbox/pyproject.toml && \
    sed -i '/numpy/d' /opt/chatterbox/pyproject.toml && \
    /opt/ComfyUI/.venv/bin/pip install --no-build-isolation /opt/chatterbox && \
    # Run pip freeze to capture state after chatterbox installation
    pip freeze > /opt/pip_freeze_after_chatterbox.txt && \
    # Use fix_conflicts.py to update chatterbox dependencies to match frozen versions
    python3 /opt/fix_conflicts.py
RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.__file__, torch.version.cuda, torch.cuda.is_available(), torch.device(torch.cuda.current_device()) )"
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/comfy --skip-prompt --no-enable-telemetry node install https://github.com/filliptm/ComfyUI_Fill-ChatterBox

RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.__file__, torch.version.cuda, torch.cuda.is_available(), torch.device(torch.cuda.current_device()) )"

# video + image

# install flashinfer for LightX2V
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu \
    git clone --depth=1 --recursive https://github.com/flashinfer-ai/flashinfer /opt/flashinfer && \
    /opt/ComfyUI/.venv/bin/uv pip install --no-build-isolation -r /opt/flashinfer/requirements.txt && \
    # Run pip freeze to capture state after flashinfer requirements installation
    pip freeze > /opt/pip_freeze_after_flashinfer_requirements.txt && \
    /opt/ComfyUI/.venv/bin/uv pip install --no-build-isolation /opt/flashinfer && \
    # Run pip freeze to capture state after flashinfer installation
    pip freeze > /opt/pip_freeze_after_flashinfer.txt && \
    # Use fix_conflicts.py to update flashinfer dependencies to match frozen versions
    python3 /opt/fix_conflicts.py && \
    /opt/ComfyUI/.venv/bin/python3 -c "import torch; from flashinfer import BatchDecodeWithPagedKVCacheWrapper; print('flashinfer OK, CUDA:', torch.cuda.is_available())" && \
    /opt/ComfyUI/.venv/bin/python3 -c "from flashinfer.rope import apply_rope_with_cos_sin_cache_inplace; print('flashinfer.rope OK')"

# ugly hack, need host .so =(
COPY comfyui/*.so /usr/local/cuda-13.0/lib64/

# install decord from sources for LightX2V + NVidia codecs, cause not available for arm64 ;( and need patch for cuda-13
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu git clone --jobs ${NPROC} --depth 1 --recursive https://github.com/johndpope/decord-cuda12.git /opt/decord && \
    cd /opt/decord && \
    # AVCodec* -> const AVCodec* for FFmpeg 5.6x
    sed -i 's/AVCodec \*dec;/const AVCodec *dec;/g' src/video/video_reader.cc && \
    sed -i 's/AVCodec \*dec = NULL;/const AVCodec *dec = NULL;/g' src/video/video_reader.cc && \
    sed -i 's/AVCodec\* dec;/const AVCodec* dec;/g' src/video/video_reader.cc && \
    sed -i 's/AVCodec\* dec = NULL;/const AVCodec* dec = NULL;/g' src/video/video_reader.cc && \
    sed -i 's/AVCodec \* dec;/const AVCodec * dec;/g' src/video/video_reader.cc && \
    sed -i 's/AVCodec \* dec = NULL;/const AVCodec * dec = NULL;/g' src/video/video_reader.cc && \
    # universal patch
    perl -i -pe 's/\bAVCodec\s*\*\s*dec\b/const AVCodec *dec/g' src/video/video_reader.cc && \
    mkdir build && cd build && \
    cmake .. -DUSE_CUDA=ON -DCMAKE_BUILD_TYPE=Release \
        -DCMAKE_CUDA_COMPILER=/usr/local/cuda-13.0/bin/nvcc \
        -DCMAKE_CUDA_ARCHITECTURES=121 && \
    ninja && \
    /opt/ComfyUI/.venv/bin/pip install --no-build-isolation /opt/decord/python/ && \
    # Run pip freeze to capture state after decord installation
    pip freeze > /opt/pip_freeze_after_decord.txt && \
    # Use fix_conflicts.py to update decord dependencies to match frozen versions
    python3 /opt/fix_conflicts.py && \
    /opt/ComfyUI/.venv/bin/python3 -c "from decord import VideoReader, gpu; print('decord OK')"

# Install LightX2V
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu \
    git clone --recursive --jobs ${NPROC} --depth 1 https://github.com/ModelTC/LightX2V.git /opt/LightX2V && \
    sed -i '/"decord/d' /opt/LightX2V/pyproject.toml && \
    sed -i '/decord/d' /opt/LightX2V/requirements.txt && \
    sed -i '/"torch/d' /opt/LightX2V/pyproject.toml && \
    sed -i '/^torch/d' /opt/LightX2V/requirements.txt && \
    sed -i '/^torchvision/d' /opt/LightX2V/requirements.txt && \
    sed -i '/^torchaudio/d' /opt/LightX2V/requirements.txt && \
    /opt/ComfyUI/.venv/bin/pip install --no-build-isolation /opt/LightX2V && \
    # Run pip freeze to capture state after LightX2V installation
    pip freeze > /opt/pip_freeze_after_lightx2v.txt && \
    # Use fix_conflicts.py to update LightX2V dependencies to match frozen versions
    python3 /opt/fix_conflicts.py && \
    /opt/ComfyUI/.venv/bin/python3 -c "from lightx2v import LightX2VPipeline; print('lightx2v OK')"

RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.__file__, torch.version.cuda, torch.cuda.is_available(), torch.device(torch.cuda.current_device()) )"


RUN --device=nvidia.com/gpu git clone --depth=1 --recurse-submodules https://github.com/gaclove/ComfyUI-Lightx2vWrapper.git /opt/ComfyUI/custom_nodes/ComfyUI-Lightx2vWrapper

# Install Lightx2vWrapper dependencies with remove decord and torch, for compatibility issues
# First, copy the requirements files and modify them to remove problematic decord dependency
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu cd /opt/ComfyUI/custom_nodes/ComfyUI-Lightx2vWrapper && \
    grep -v -E '^decord|^torch' lightx2v/requirements.txt > lightx2v/requirements_filtered.txt && \
    grep -v -E '^decord|^torch' requirements.txt > requirements_filtered.txt && \
    /opt/ComfyUI/.venv/bin/pip install --break-system-packages --no-deps -r lightx2v/requirements_filtered.txt && \
    /opt/ComfyUI/.venv/bin/pip install --break-system-packages --no-deps -r requirements_filtered.txt

RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.__file__, torch.version.cuda, torch.cuda.is_available(), torch.device(torch.cuda.current_device()) )"

# Image to 3D 
# Clone ComfyUI-TRELLIS2 directly and install it to ensure CUDA detection works
# manually install, based on https://github.com/PozzettiAndrea/nvdiffrec_render-wheels/blob/main/.github/workflows/build-cu130-torch291.yml 
# todo remove all before install.py, after fix https://github.com/PozzettiAndrea/nvdiffrec_render-wheels/issues/1 and https://github.com/PozzettiAndrea/ComfyUI-TRELLIS2/issues/38 
RUN git clone --depth=1 https://github.com/PozzettiAndrea/ComfyUI-TRELLIS2 /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2
RUN grep -vE '^\s*#' /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2/requirements.txt | grep -viE '^\s*(torch|torchvision|torchaudio)\b' > /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2/requirements.no_torch.txt
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu uv pip install -r /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2/requirements.no_torch.txt
# Run pip freeze to capture state after ComfyUI-TRELLIS2 requirements installation
RUN pip freeze > /opt/pip_freeze_after_trellis2_requirements.txt
# Use fix_conflicts.py to update TRELLIS2 dependencies to match frozen versions
RUN python3 /opt/fix_conflicts.py

RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.__file__, torch.version.cuda, torch.cuda.is_available(), torch.device(torch.cuda.current_device()) )"

RUN git clone --depth=1 https://github.com/PozzettiAndrea/nvdiffrec_render-wheels/ /opt/nvdiffrec_render-wheels/ && \
    cd /opt/nvdiffrec_render-wheels/ && \
    git clone --depth=1 https://github.com/NVlabs/nvdiffrec.git && \
    mkdir -p nvdiffrec_render_pkg && \
    cp -rf nvdiffrec/render nvdiffrec_render_pkg/nvdiffrec_render && \
    cp -vf setup.py nvdiffrec_render_pkg/
# replace JIT compilation to static import
COPY comfyui/nvdiffrec_ops.py /opt/nvdiffrec_render-wheels/nvdiffrec_render_pkg/nvdiffrec_render/renderutils/ops.py


RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu cd /opt/nvdiffrec_render-wheels/nvdiffrec_render_pkg && \
    # Modify setup.py to set CUDA environment variables before importing CUDAExtension \
    sed -i '1i import os, sys' setup.py && \
    sed -i '2i os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-13.0\"' setup.py && \
    sed -i '3i os.environ[\"CUDA_PATH\"] = \"/usr/local/cuda-13.0\"' setup.py && \
    sed -i '4i sys.path.insert(0, \"/usr/local/cuda-13.0/lib64\")' setup.py && \
    echo "CUDA_HOME is set to: $CUDA_HOME" && \
    /opt/ComfyUI/.venv/bin/python setup.py build_ext --inplace && \
    /opt/ComfyUI/.venv/bin/pip install --no-build-isolation . && \
    # Run pip freeze to capture state after nvdiffrec_render installation
    pip freeze > /opt/pip_freeze_after_nvdiffrec_render.txt && \
    # Use fix_conflicts.py to update nvdiffrec_render dependencies to match frozen versions
    python3 /opt/fix_conflicts.py
RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "from nvdiffrec_render.renderutils import _C; print('nvdiffrec_render OK:', _C.__file__)"    


# Run the installation with parallel build settings
RUN --mount=type=cache,id=comfyui-cache,target=/root/.cache/ --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 /opt/ComfyUI/custom_nodes/ComfyUI-TRELLIS2/install.py
# Run pip freeze to capture final state
RUN pip freeze > /opt/pip_freeze_final.txt
# Use fix_conflicts.py to update all dependencies to match frozen versions
RUN python3 /opt/fix_conflicts.py


# check torch with CUDA versions
RUN --device=nvidia.com/gpu /opt/ComfyUI/.venv/bin/python3 -c "import torch; print('VENV', torch.__version__, torch.__file__, torch.version.cuda, torch.cuda.is_available(), torch.device(torch.cuda.current_device()) )"

COPY comfyui/extra_model_paths.yaml /opt/ComfyUI/
# TODO Install ComfyUI models 

CMD ["/opt/ComfyUI/.venv/bin/python3", "main.py", "--enable-manager","--preview-method", "auto", "--front-end-version","Comfy-Org/ComfyUI_frontend@latest"]

EXPOSE 8188

